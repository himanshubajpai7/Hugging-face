{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark NLP- Text classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "o3qkiSEaWENr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44B_JtXmyOuF"
      },
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment analysis of data with multiple sentiment-classes"
      ],
      "metadata": {
        "id": "g4AVrVpTnM_S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mc2rld9f7YW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f4598b-983d-40cf-e2da-ec36e61ebde6"
      },
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 61 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 38.7 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "KjcBNzFVgoky",
        "outputId": "3fd53f4a-b536-4c1b-fa85-cfa8910c88e8"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(gpu = True) \n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.3.1\n",
            "Apache Spark version: 3.1.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://50fa3c340213:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7227b1b1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3qkiSEaWENr"
      },
      "source": [
        "## ClassiferDL with Word Embeddings and Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTK1AsahOpz"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEYijaovgw3M"
      },
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0u9cOqqhS4w",
        "outputId": "69e7da52-dc9c-4f8d-8d09-63a0d716f542"
      },
      "source": [
        "!ls -lt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24948\n",
            "-rw-r--r-- 1 root root  1504408 Oct 11 09:56 news_category_test.csv\n",
            "-rw-r--r-- 1 root root 24032125 Oct 11 09:56 news_category_train.csv\n",
            "drwxr-xr-x 1 root root     4096 Sep 30 17:12 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoTE46WThUz2",
        "outputId": "d0414bd6-8998-40ac-97b6-4173c6687473"
      },
      "source": [
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_train.csv\")\n",
        "\n",
        "trainDataset.show(truncate=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business| Short sellers, Wall Street's dwindling band of...|\n",
            "|Business| Private investment firm Carlyle Group, which h...|\n",
            "|Business| Soaring crude prices plus worries about the ec...|\n",
            "|Business| Authorities have halted oil export flows from ...|\n",
            "|Business| Tearaway world oil prices, toppling records an...|\n",
            "|Business| Stocks ended slightly higher on Friday but sta...|\n",
            "|Business| Assets of the nation's retail money market mut...|\n",
            "|Business| Retail sales bounced back a bit in July, and n...|\n",
            "|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n",
            "|Business| Short sellers, Wall Street's dwindling  band o...|\n",
            "|Business| Soaring crude prices plus worries  about the e...|\n",
            "|Business| OPEC can do nothing to douse scorching  oil pr...|\n",
            "|Business| Non OPEC oil exporters should consider  increa...|\n",
            "|Business| WASHINGTON/NEW YORK (Reuters) - The auction fo...|\n",
            "|Business| The dollar tumbled broadly on Friday  after da...|\n",
            "|Business|If you think you may need to help your elderly ...|\n",
            "|Business|The purchasing power of kids is a big part of w...|\n",
            "|Business|There is little cause for celebration in the st...|\n",
            "|Business|The US trade deficit has exploded 19 to a recor...|\n",
            "|Business|Oil giant Shell could be bracing itself for a t...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3iINSk1hc2E",
        "outputId": "3b1c0ee1-90af-467b-bf3f-c12464d7871b"
      },
      "source": [
        "trainDataset.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEaUJ3xzhgLf",
        "outputId": "a43d6547-e807-454e-ae2d-786770d53fdc"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "trainDataset.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|Sci/Tech|30000|\n",
            "|   World|30000|\n",
            "|  Sports|30000|\n",
            "|Business|30000|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mk82Fnkhj4N",
        "outputId": "1ce9f210-f30f-40e5-e651-ce420ee990fe"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "testDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_test.csv\")\n",
        "\n",
        "\n",
        "testDataset.groupBy(\"category\") \\\n",
        "      .count() \\\n",
        "      .orderBy(col(\"count\").desc()) \\\n",
        "      .show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|Sci/Tech| 1900|\n",
            "|   World| 1900|\n",
            "|  Sports| 1900|\n",
            "|Business| 1900|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nHTo9Fxjjwq"
      },
      "source": [
        "# if we want to split the dataset\n",
        "'''\n",
        "(trainingData, testData) = trainDataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AkxJDshietW",
        "outputId": "0b727129-2783-4e0d-f700-42729be2f896"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"normalized\")\\\n",
        "    .setOutputCol(\"cleanTokens\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX-LjXhvY2EV"
      },
      "source": [
        "### with Glove 100d embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6PJxX4JY1S-",
        "outputId": "a196f539-9788-44aa-a01c-7fcb46cdd627"
      },
      "source": [
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'lemma'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"category\")\\\n",
        "      .setMaxEpochs(3)\\\n",
        "      .setEnableOutputLogs(True)\n",
        "      #.setOutputLogsPath('logs')\n",
        "\n",
        "clf_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0lwLD_hZkrI"
      },
      "source": [
        "'''\n",
        "default classifierDL params:\n",
        "\n",
        "    maxEpochs -> 10,\n",
        "    lr -> 5e-3f,\n",
        "    dropout -> 0.5f,\n",
        "    batchSize -> 64,\n",
        "    enableOutputLogs -> false,\n",
        "    verbose -> Verbose.Silent.id,\n",
        "    validationSplit -> 0.0f,\n",
        "    outputLogsPath -> \"\"\n",
        "    \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QKnwlFNi2A6",
        "outputId": "316c0a53-54c6-49f3-df14-09b392bd0112"
      },
      "source": [
        "# Train (3 min for 3 epochs)\n",
        "%%time\n",
        "\n",
        "clf_pipelineModel = clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.15 s, sys: 142 ms, total: 1.29 s\n",
            "Wall time: 3min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "693tFCxy9gQ8",
        "outputId": "cc086d08-951e-4320-ffb5-a671cb47551f"
      },
      "source": [
        "import os\n",
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "\n",
        "with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n",
        "    print(log_file.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 3 - learning_rate: 0.005 - batch_size: 64 - training_examples: 120000 - classes: 4\n",
            "Epoch 0/3 - 28.43s - loss: 1614.0685 - acc: 0.86878335 - batches: 1875\n",
            "Epoch 1/3 - 26.76s - loss: 1594.4856 - acc: 0.88203335 - batches: 1875\n",
            "Epoch 2/3 - 26.77s - loss: 1590.2032 - acc: 0.88668334 - batches: 1875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvJDn6C6j8BK"
      },
      "source": [
        "# get the predictions on test Set\n",
        "\n",
        "preds = clf_pipelineModel.transform(testDataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XdH8Z3ljYpx",
        "outputId": "50a57ad1-f3f3-4b13-c95c-eef95cc0c6d8"
      },
      "source": [
        "preds.select('category','description',\"class.result\").show(10, truncate=80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------------------------------------+----------+\n",
            "|category|                                                                     description|    result|\n",
            "+--------+--------------------------------------------------------------------------------+----------+\n",
            "|Business|Unions representing workers at Turner   Newall say they are 'disappointed' af...|[Business]|\n",
            "|Sci/Tech| TORONTO, Canada    A second team of rocketeers competing for the  #36;10 mil...|[Sci/Tech]|\n",
            "|Sci/Tech| A company founded by a chemistry researcher at the University of Louisville ...|[Sci/Tech]|\n",
            "|Sci/Tech| It's barely dawn when Mike Fitzpatrick starts his shift with a blur of color...|[Sci/Tech]|\n",
            "|Sci/Tech| Southern California's smog fighting agency went after emissions of the bovin...|   [World]|\n",
            "|Sci/Tech|\"The British Department for Education and Skills (DfES) recently launched a \"...|[Sci/Tech]|\n",
            "|Sci/Tech|\"confessed author of the Netsky and Sasser viruses, is responsible for 70 per...|[Sci/Tech]|\n",
            "|Sci/Tech|\\\\FOAF/LOAF  and bloom filters have a lot of interesting properties for socia...|[Sci/Tech]|\n",
            "|Sci/Tech|\"Wiltshire Police warns about \"\"phishing\"\" after its fraud squad chief was ta...|[Sci/Tech]|\n",
            "|Sci/Tech|In its first two years, the UK's dedicated card fraud unit, has recovered 36,...|[Sci/Tech]|\n",
            "+--------+--------------------------------------------------------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZh8gMZEk0Dy"
      },
      "source": [
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VqF8O6ilB__",
        "outputId": "6257af99-7e9d-49a6-9a5a-26dbb8dff975"
      },
      "source": [
        "# We are going to use sklearn to evalute the results on test dataset\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print (classification_report(preds_df['result'], preds_df['category']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.84      0.83      0.84      1915\n",
            "    Sci/Tech       0.86      0.84      0.85      1957\n",
            "      Sports       0.97      0.94      0.95      1955\n",
            "       World       0.86      0.92      0.89      1773\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9tXlaLYpwdG"
      },
      "source": [
        "## Getting prediction from Trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNERYucrncR5"
      },
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "\n",
        "light_model = LightPipeline(use_pipelineModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBztNjY14FKn",
        "outputId": "82a7c5b0-4ccc-42a2-9733-c256845c4ed2"
      },
      "source": [
        "testDataset.select('description').take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(description=\"Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"),\n",
              " Row(description=' TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for privately funded suborbital space flight, has officially announced the first launch date for its manned rocket.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlkv_Af4Ie8",
        "outputId": "9945fe7d-13e4-49c6-cb09-bd3c647bec46"
      },
      "source": [
        "text='''\n",
        "Fearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions. \n",
        "As of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\n",
        "'''\n",
        "result = light_model.annotate(text)\n",
        "\n",
        "result['class']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['World']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3OTJAYq4MwR",
        "outputId": "786f2779-899b-4bab-e282-bb0ea0f8957e"
      },
      "source": [
        "light_model.annotate('the soccer games will be postponed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': ['Sports'],\n",
              " 'document': ['the soccer games will be postponed.'],\n",
              " 'sentence_embeddings': ['the soccer games will be postponed.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xgbU0Gzqraz"
      },
      "source": [
        "# SentimentDL Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inuIcH5sq_5H"
      },
      "source": [
        "!wget -q aclimdb_train.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_train.csv\n",
        "!wget -q aclimdb_test.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1-7tMKnrFF2",
        "outputId": "23a3f5a7-da53-4194-f297-0084fa8c7c33"
      },
      "source": [
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"aclimdb_train.csv\")\n",
        "\n",
        "trainDataset.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+\n",
            "|                text|   label|\n",
            "+--------------------+--------+\n",
            "|This is an Excell...|positive|\n",
            "|The Sarah Silverm...|positive|\n",
            "|\"Prom Night\" is a...|negative|\n",
            "|So often a band w...|positive|\n",
            "|\"Pet Sematary\" is...|positive|\n",
            "|I watched the fil...|negative|\n",
            "|Boy this movie ha...|negative|\n",
            "|Checking the spoi...|negative|\n",
            "|Despite its rathe...|positive|\n",
            "|Absolute masterpi...|positive|\n",
            "|The tweedy profes...|positive|\n",
            "|A movie best summ...|negative|\n",
            "|Take young, prett...|negative|\n",
            "|For months I've b...|negative|\n",
            "|\"Batman: The Myst...|positive|\n",
            "|Well, it was funn...|negative|\n",
            "|I have seen the s...|positive|\n",
            "|Brainless film ab...|negative|\n",
            "|Leave it to geniu...|negative|\n",
            "|Seven Pounds star...|positive|\n",
            "+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHVXJvW18g8i",
        "outputId": "6ec36863-1253-4ac1-ad67-1251ba3ec37c"
      },
      "source": [
        "testDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"aclimdb_test.csv\")\n",
        "\n",
        "testDataset.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+\n",
            "|                text|   label|\n",
            "+--------------------+--------+\n",
            "|The Second Woman ...|negative|\n",
            "|In my opinion the...|positive|\n",
            "|I am listening to...|positive|\n",
            "|Before I speak my...|negative|\n",
            "|ManBearPig is a p...|positive|\n",
            "|A buddy and I wen...|negative|\n",
            "|It is incredible ...|negative|\n",
            "|Dire! Dismal! Awf...|negative|\n",
            "|HLOTS was an outs...|positive|\n",
            "|This is just one ...|negative|\n",
            "|This movie had th...|negative|\n",
            "|The 80s were over...|positive|\n",
            "|The tunes are the...|positive|\n",
            "|Having recently s...|positive|\n",
            "|My favorite film ...|positive|\n",
            "|This movie just m...|positive|\n",
            "|This is the worst...|negative|\n",
            "|This was a nice f...|positive|\n",
            "|I don't know, may...|negative|\n",
            "|After wasting 2 h...|negative|\n",
            "+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bhQyIKOqwZJ",
        "outputId": "89e73d33-e75b-46d3-f437-f0d14115dd2b"
      },
      "source": [
        "# actual content is inside description column\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained(\"tfhub_use_lg\", \"en\") \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# the classes/labels/categories are in category column\n",
        "sentimentdl = SentimentDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        sentimentdl\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use_lg download started this may take some time.\n",
            "Approximate size to download 753.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOxevkKrSC1",
        "outputId": "88d5567f-4218-4b55-81cd-71ce3718a3de"
      },
      "source": [
        "%%time\n",
        "pipelineModel = pipeline.fit(trainDataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.9 s, sys: 1.37 s, total: 14.3 s\n",
            "Wall time: 42min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-wOcQkl8erj"
      },
      "source": [
        "result = pipelineModel.transform(testDataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maHT9M0M9Cpf"
      },
      "source": [
        "result_df = result.select('text','label',\"class.result\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "lSJs_oBkBxSd",
        "outputId": "aeb6a632-ba9c-4a1e-d0c4-013034a6b53e"
      },
      "source": [
        "result_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Second Woman is about the story of a myste...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In my opinion the directing, editing, lighting...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am listening to Istanbul, intent, my eyes cl...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Before I speak my piece, I would like to make ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[neutral]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ManBearPig is a pretty funny episode of South ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[neutral]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A buddy and I went to see this movie when it c...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>It is incredible that there were two films wit...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Dire! Dismal! Awful! Laughable! Disappointing!...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HLOTS was an outstanding series, its what NYPD...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>This is just one of those films which cannot j...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     label      result\n",
              "0  The Second Woman is about the story of a myste...  negative  [positive]\n",
              "1  In my opinion the directing, editing, lighting...  positive  [positive]\n",
              "2  I am listening to Istanbul, intent, my eyes cl...  positive  [positive]\n",
              "3  Before I speak my piece, I would like to make ...  negative   [neutral]\n",
              "4  ManBearPig is a pretty funny episode of South ...  positive   [neutral]\n",
              "5  A buddy and I went to see this movie when it c...  negative  [negative]\n",
              "6  It is incredible that there were two films wit...  negative  [negative]\n",
              "7  Dire! Dismal! Awful! Laughable! Disappointing!...  negative  [negative]\n",
              "8  HLOTS was an outstanding series, its what NYPD...  positive  [positive]\n",
              "9  This is just one of those films which cannot j...  negative  [negative]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}